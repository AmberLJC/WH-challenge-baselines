"""
Author: Galen Harrison (gh7vp@virginia.edu)
Date: 2022-08-11

Take random walks generated by rwr_all.py (dictionaries mapping pids -> subgraphs)
and generate the data consumed by the DeepInf model.
"""
import os
from pickle import load
from argparse import ArgumentParser
from glob import glob

import pandas as pd
import numpy as np

DELTA = 7 # how far a period to look ahead for
PAST_WINDOW = 3 # how far back to look for infection status

def write_vertex_features(vertex_features, subgraph, age_map):
    # for each node in subgraph, write features to vertex_features
    # age
    # coreness
    # authority
    # rareness
    subgraph_pids = subgraph.vs["name"]
    
    coreness = subgraph.coreness()
    authority = subgraph.authority_score(weights="duration")
    degrees = np.array([subgraph.degree(i) for i in range(len(subgraph_pids))])

    zero_degrees = degrees == 0
    degrees[zero_degrees] = 1
    rareness = 1.0/degrees
    rareness[zero_degrees] = 0
    
    vertex_features[tuple(subgraph_pids), 0] = [age_map[pid] for pid in subgraph_pids]
    vertex_features[tuple(subgraph_pids), 1] = [coreness[subgraph.vs.find(name=pid).index] for pid in subgraph_pids]
    vertex_features[tuple(subgraph_pids), 2] = [authority[subgraph.vs.find(name=pid).index] for pid in subgraph_pids]

    vertex_features[tuple(subgraph_pids), 3] = rareness
    
    return vertex_features

def make_si_table(disease_data):
    """
    make table of all infections indexed by pid and infected (day of infection)
    """
    is_infected = disease_data["state"] == "I"
    pid = disease_data[is_infected]["pid"]
    day = disease_data[is_infected]["day"]

    inf_time_df = pd.DataFrame({"pid" : pid, "day" : day})

    is_rec = disease_data["state"] == "R"
    pid = disease_data[is_rec]["pid"]
    day = disease_data[is_rec]["day"]

    rec_time_df = pd.DataFrame({"pid" : pid, "day" : day})

    def lookup_rec(row):
        pid_subset = rec_time_df[(rec_time_df["pid"] == row["pid"]) & (rec_time_df["day"] >= row["day"])]
        return pid_subset["day"].min()

    recovery_times = inf_time_df.apply(lookup_rec, axis=1)
    si_table = inf_time_df
    si_table.rename({"day" : "infected"}, axis=1, inplace=True)
    si_table["recovery"] = recovery_times 

    si_table.set_index(["pid", "infected"], verify_integrity=True, inplace=True)

    return si_table

def process_subgraph(subgraph, si_table, age_map, vertex_features, ego_pid, cutoff=None, max_size=50):

    # for each infected node in subgraph create
    # a positive instance, at time t-delta

    # create a negative instance for neighbors not infected at time - delta

    subgraph_pids = subgraph.vs["name"]
    si_subgraph = si_table[si_table.index.get_level_values("pid").isin(subgraph_pids)]

    if len(si_subgraph) == 0:
        return None

    pid_arr = np.pad(np.array(subgraph_pids), (0, max_size-len(subgraph_pids)), "constant", constant_values=0)
    valid_days = si_subgraph.index.get_level_values("infected")
    if cutoff:
        valid_days = valid_days[valid_days >= cutoff]

    n = len(valid_days.unique())

    labels = np.zeros((n,), dtype=int)
    influence_feature = np.zeros((n,max_size,2))
    adjacency_matrix = np.zeros((n,max_size, max_size))
    vertex_id = np.zeros((n,max_size), dtype=int)

    subgraph_adj = np.array(subgraph.get_adjacency().data)
    pad_num = max_size - subgraph_adj.shape[0]  
    adj = np.pad(subgraph_adj, (0,pad_num), "constant", constant_values=0)
    
    vertex_features = write_vertex_features(vertex_features, subgraph, age_map)
    
    label_idx = 0

    for day in valid_days.unique():
        # look forward delta steps to identify 
        min_day = day - PAST_WINDOW

        day_level = si_subgraph.index.get_level_values("infected").to_series()
        back_subgraph = si_subgraph[day_level.between(min_day, day).values]
    
        state_t_d = si_subgraph[day_level.between(day, day+DELTA, inclusive="right").values]

        labels[label_idx] = ego_pid in state_t_d.index.get_level_values("pid")
        adjacency_matrix[label_idx] = adj
        vertex_id[label_idx] = pid_arr

        influence_feature[label_idx,:,0] = (pid_arr == ego_pid).astype(int)

        # get neighbors who are infected at time t-delta 
        is_inf = np.isin(pid_arr, back_subgraph.index.get_level_values("pid").unique()).astype(int)
        influence_feature[label_idx,:,1] = is_inf
       
        label_idx += 1
 
    return (labels, adjacency_matrix, influence_feature, vertex_id, vertex_features)

if __name__ == "__main__":
   
    parser = ArgumentParser()
    parser.add_argument("subgraph_dir", help="directory with .rwr_table files")
    parser.add_argument("--disease-file", required=True, help="File with health states over time")
    parser.add_argument("--pop-file", required=True, help="population file")
    parser.add_argument("output", help="output directory")
    parser.add_argument("--sample_size", type=int, default=5, help="number of pids to sample from")
    parser.add_argument("--test-set", default=False, action="store_true", help="are you generating a test set or not?")
    parser.add_argument("--test-date-start", type=int, help="start date for test data")
    args = parser.parse_args()

    # read in population file
    pop_file = pd.read_csv(args.pop_file)
    age_map = pop_file[["pid", "age"]].set_index("pid")["age"].to_dict()
    max_id = max(age_map.keys())
    print(f"Made age map, {max_id} is the max_id")
    vertex_features = np.zeros((max_id+1, 4))

    # read in subgraph list
    disease_df = pd.read_csv(args.disease_file)
    si_table = make_si_table(disease_df)

    print("Created SI table")
    excl_pids = set()

    if args.test_set:
        # select instances not infected 
        train_set = si_table[si_table.index.get_level_values("infected") <= args.test_date_start - PAST_WINDOW]
        inf_pids = train_set.index.get_level_values("pid").unique()
        not_already_inf = si_table[~si_table.index.get_level_values("pid").isin(inf_pids)]
        test_set = not_already_inf[not_already_inf.index.get_level_values("infected") > (args.test_date_start - PAST_WINDOW)]
        excl_pids.update(inf_pids)

        si = test_set 

    else:
        si = si_table
    print(f"Found {len(si)} disease instances, {len(excl_pids)} excluded")
    file_list = glob(os.path.join(args.subgraph_dir, "*.rwr_table"))
    print(f"Extracting {file_list[0]}, to {file_list[-1]}")
    subgraphs = {}
    for filename in file_list:
        # if ego pid is infected, then add to list
        with open(filename, "rb") as subgraph_file:
            subgraph_dict = load(subgraph_file) 
        subgraphs.update({pid : graph for pid, graph in subgraph_dict.items() if pid not in excl_pids})

    print(f"There are {len(subgraphs)} subgraphs") 
    index_set = np.random.choice(list(subgraphs.keys()), replace=False, size=min(args.sample_size, len(subgraphs))) 

    label_list = []
    adj_list = []
    inf_list = []
    vert_id = []
      
    for i,subgraph_pid in enumerate(index_set): 

        subgraph = subgraphs[subgraph_pid]
        output = process_subgraph(subgraph, si, age_map, vertex_features, subgraph_pid, args.test_date_start)

        if output is not None:
            labels, adjacency_matrix, influence_feature, vertex_id, vertex_features = output

            label_list.append(labels)
            adj_list.append(adjacency_matrix)
            inf_list.append(influence_feature)
            vert_id.append(vertex_id)

        if (i+1) % 100 == 0:
            print(f"Handled {i}/{len(index_set)} instances, {len(label_list)} added")

    if len(label_list) > 0:
        np.save(os.path.join(args.output, "label.npy"), np.concatenate(label_list, dtype=int)) 
    if len(vert_id) > 0: 
        np.save(os.path.join(args.output, "vertex_id.npy"), np.concatenate(vert_id))
    if len(adj_list) > 0: 
        np.save(os.path.join(args.output, "adjacency_matrix.npy"), np.concatenate(adj_list))
    if len(inf_list) > 0:
        np.save(os.path.join(args.output, "influence_feature.npy"), np.concatenate(inf_list))

    np.save(os.path.join(args.output, "vertex_features.npy"), vertex_features)
